{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import make_column_selector\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('merged_df.csv', index_col=None)\n",
    "\n",
    "# remove outliers\n",
    "# remove absence_range, finalResult, \n",
    "df = df.drop(['absences_range', 'finalResult'], axis=1)\n",
    "df = df[df['absences'] < 20]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns pre selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  transform all non object to object type\n",
    "df[['Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel','freetime', 'goout', \n",
    "    'Dalc', 'Walc', 'health']] = df[['Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel','freetime', 'goout', 'Dalc', 'Walc', 'health']].astype('object') \n",
    "\n",
    "columns_cat = df[['school', 'sex', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu',\n",
    "       'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime',\n",
    "       'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery',\n",
    "       'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc',\n",
    "       'Walc', 'health']]\n",
    "\n",
    "continue_cols = df[['age','absences']]\n",
    "\n",
    "# cocat in a new dataframe\n",
    "df_cat = pd.concat([columns_cat, continue_cols], axis=1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns transformation and encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_cat\n",
    "ct = make_column_transformer(\n",
    "      (MinMaxScaler(),\n",
    "       make_column_selector(dtype_include=np.number)),\n",
    "      (OneHotEncoder(),\n",
    "       make_column_selector(dtype_include=object)))\n",
    "\n",
    "# Apply the column transformer to the data\n",
    "X_preprocessed = ct.fit_transform(X)  \n",
    "\n",
    "# Create a new dataframe with the preprocessing applied\n",
    "feature_names = ct.get_feature_names_out()\n",
    "new_df = pd.DataFrame(X_preprocessed, columns=feature_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "X = new_df\n",
    "y = df['G3']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to train and fine tune a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(X_train, X_test, y_train, y_test):\n",
    "    # Create preprocessing pipeline\n",
    "    preprocessing_pipeline = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', MinMaxScaler(), make_column_selector(dtype_include=np.number)),\n",
    "            ('cat', OneHotEncoder(), make_column_selector(dtype_include=object))\n",
    "        ])\n",
    "\n",
    "    # Create pipelines for each model\n",
    "    knn_pipeline = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessing_pipeline),\n",
    "        ('regressor', KNeighborsRegressor())\n",
    "    ])\n",
    "\n",
    "    dt_pipeline = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessing_pipeline),\n",
    "        ('regressor', DecisionTreeRegressor())\n",
    "    ])\n",
    "\n",
    "    # Define hyperparameter search spaces for each pipeline\n",
    "    knn_params = {'regressor__n_neighbors': [3, 5, 7, 9, 11],\n",
    "                  'regressor__weights': ['uniform', 'distance'],\n",
    "                  'regressor__algorithm': ['ball_tree', 'kd_tree', 'brute'],\n",
    "                  'regressor__leaf_size': [10, 20, 30, 40, 50],\n",
    "                  'regressor__p': [1, 2]}\n",
    "\n",
    "    dt_params = {'regressor__criterion': ['friedman_mse', 'squared_error', 'poisson', 'absolute_error'],\n",
    "                 'regressor__splitter': ['best', 'random'],\n",
    "                 'regressor__max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "                 'regressor__min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "                 'regressor__min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}\n",
    "\n",
    "    # Create a dictionary containing all the pipelines and their corresponding hyperparameter search spaces\n",
    "    pipelines = {\n",
    "        'knn': (knn_pipeline, knn_params),\n",
    "        'dt': (dt_pipeline, dt_params)\n",
    "    }\n",
    "\n",
    "    # Create lists to store the pipeline names, MSE values, and R-squared values\n",
    "    pipeline_names = []\n",
    "    mse_values = []\n",
    "    r2_values = []\n",
    "\n",
    "    # Perform grid search for each pipeline\n",
    "    for pipeline_name, (pipeline, param_grid) in pipelines.items():\n",
    "        print(f\"Performing grid search for pipeline: {pipeline_name}\")\n",
    "        grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        y_pred = grid_search.predict(X_test)\n",
    "\n",
    "        # Compute metrics\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "        # Add pipeline name, MSE value, and R-squared value to the lists\n",
    "        pipeline_names.append(pipeline_name)\n",
    "        mse_values.append(mse)\n",
    "        r2_values.append(r2)\n",
    "\n",
    "        print(f\"Best parameters for {pipeline_name}: {grid_search.best_params_}\")\n",
    "        print(f\"Mean squared error: {mse:.3f}\")\n",
    "        print(f\"R-squared: {r2:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search for pipeline: knn\n",
      "Best parameters for knn: {'regressor__algorithm': 'kd_tree', 'regressor__leaf_size': 20, 'regressor__n_neighbors': 11, 'regressor__p': 2, 'regressor__weights': 'uniform'}\n",
      "Mean squared error: 14.029\n",
      "R-squared: 0.057\n",
      "Performing grid search for pipeline: dt\n"
     ]
    }
   ],
   "source": [
    "evaluate_models(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot with the best model\n",
    "plt.scatter(y_test, y_pred, color='red')\n",
    "plt.plot(y_test, y_test, color='blue')\n",
    "\n",
    "# assuming y_test and y_pred are defined from your code\n",
    "plt.scatter(y_test, y_pred, color='red')\n",
    "plt.plot(y_test, y_test, color='blue')\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')\n",
    "plt.title('True vs. Predicted Values')\n",
    "# display the distance between the line and the points\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create scatter plot with regression line using Seaborn\n",
    "sns.regplot(x=y_test, y=y_pred, color='red')\n",
    "\n",
    "# Add labels and title using Matplotlib\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')\n",
    "plt.title('True vs. Predicted Values')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
